{
  "dataset_revision": "50fd9d5d09edd53af89af765636be5db6f983f0e",
  "task_name": "SynPerChatbotConvSASatisfaction",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.962005,
        "f1": 0.958671,
        "f1_weighted": 0.961871,
        "ap": 0.95511,
        "ap_weighted": 0.95511,
        "scores_per_experiment": [
          {
            "accuracy": 0.960373,
            "f1": 0.956886,
            "f1_weighted": 0.96023,
            "ap": 0.953309,
            "ap_weighted": 0.953309
          },
          {
            "accuracy": 0.965035,
            "f1": 0.962067,
            "f1_weighted": 0.964961,
            "ap": 0.960116,
            "ap_weighted": 0.960116
          },
          {
            "accuracy": 0.958042,
            "f1": 0.954544,
            "f1_weighted": 0.957983,
            "ap": 0.954046,
            "ap_weighted": 0.954046
          },
          {
            "accuracy": 0.951049,
            "f1": 0.947188,
            "f1_weighted": 0.951082,
            "ap": 0.950065,
            "ap_weighted": 0.950065
          },
          {
            "accuracy": 0.969697,
            "f1": 0.966836,
            "f1_weighted": 0.969493,
            "ap": 0.958615,
            "ap_weighted": 0.958615
          },
          {
            "accuracy": 0.955711,
            "f1": 0.951814,
            "f1_weighted": 0.955551,
            "ap": 0.948617,
            "ap_weighted": 0.948617
          },
          {
            "accuracy": 0.962704,
            "f1": 0.959244,
            "f1_weighted": 0.962483,
            "ap": 0.952593,
            "ap_weighted": 0.952593
          },
          {
            "accuracy": 0.974359,
            "f1": 0.972103,
            "f1_weighted": 0.974267,
            "ap": 0.967543,
            "ap_weighted": 0.967543
          },
          {
            "accuracy": 0.95338,
            "f1": 0.948902,
            "f1_weighted": 0.953027,
            "ap": 0.941307,
            "ap_weighted": 0.941307
          },
          {
            "accuracy": 0.969697,
            "f1": 0.967125,
            "f1_weighted": 0.969633,
            "ap": 0.964885,
            "ap_weighted": 0.964885
          }
        ],
        "main_score": 0.962005,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 12.675525188446045,
  "kg_co2_emissions": null
}